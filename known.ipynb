{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "209908d14524beb7bcd7791f0d3ba160f9197be054b9bd47913d8f6fbc9b8a64"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as Detok\n",
    "from textblob.wordnet import VERB\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# \n",
    "# BW: This script can be used to extract know concepts (found in an ontology) from a transcript\n",
    "#\n",
    "\n",
    "#Open ontology-file \n",
    "ontologyFile = open('ontology/ontology.txt', 'r')\n",
    "ontology = ontologyFile.read()\n",
    "ontologyWords = ontology.split()\n",
    "\n",
    "detokenizer= Detok()\n",
    "speaker_words = {}\n",
    "speaker_pattern = re.compile(r'^(\\w+?):(.*)$')\n",
    "#Get stopwords and extend this corpus\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(['Yeah','yeah', 'Um','Well','Right', 'I', 'Yes','Uh','uh','Okay','okay', 'Sorry','sorry','Yep','yep','Uhh','uhh','Gonna', 'gonna','Gon na','gon na','Mm','mm','Wanna','Wan na','wanna','wan na','Ok','ok','OK','Oh','oh','Mhm','mhm','Sure','sure','Mhmm','mhmm','Jeez','jeez','Hi','hi','wow','Wow','True','true'])\n",
    "\n",
    "#Go through transcript and split sentences based on the different speakers\n",
    "with open(\"transcript-splitted/splitted-wd_d1_r2.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        current_speaker = None\n",
    "        for line in lines:\n",
    "                line = line.strip()\n",
    "                match = speaker_pattern.match(line)\n",
    "                if match is not None:\n",
    "                        current_speaker = match.group(1)\n",
    "                        line = match.group(2).strip()\n",
    "                        if current_speaker not in speaker_words.keys():\n",
    "                                speaker_words[current_speaker] = []\n",
    "                if current_speaker:\n",
    "                        words = [word.strip() for word in line.split(' ') if len(word.strip()) > 0]\n",
    "                        speaker_words[current_speaker].extend(words)\n",
    "\n",
    "dictget = lambda d, *k: [d[i] for i in k]\n",
    "spk_0 = dictget(speaker_words, 'spk_0')\n",
    "\n",
    "#Go through text of specific speaker, and count words if the word is found in the ontology words\n",
    "text_0 = detokenizer.detokenize(spk_0)\n",
    "count_0 = {w: 0 for w in ontologyWords}\n",
    "for index, word in enumerate(nltk.word_tokenize(text_0)):\n",
    "    if word in count_0:\n",
    "        for w in word.split():\n",
    "            count_0[w] +=1\n",
    "#Create dataframe based on counted words\n",
    "df_0 = pd.DataFrame.from_dict(count_0, orient='index').reset_index()\n",
    "df_0.columns = ['Ontology Word', 'Frequency']\n",
    "df_0.insert(2, \"Speaker\", \"spk_0\", True) \n",
    "df_0 = df_0.sort_values(by=['Frequency'], ascending=False)\n",
    "\n",
    "#Combine different tables \n",
    "frames = [df_0]\n",
    "result = pd.concat(frames)\n",
    "result_sorted = result.sort_values(by=['Frequency'], ascending=False)\n",
    "result_sorted.to_excel(\"output/known-words.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}